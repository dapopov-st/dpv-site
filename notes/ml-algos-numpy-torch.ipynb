{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Algorithms in Numpy and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: ML Algorithms in Numpy and PyTorch\n",
    "description: ML Algorithms in Numpy and PyTorch\n",
    "date: 2024-10\n",
    "categories: [PyTorch]\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import ListedColormap\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predict the class based on the most common class among the k nearest neighbors\n",
    "- fit: doesn't actually \"train\" the model in a traditional sense, just stores the training data.\n",
    "- predict: for each point, find k nearest neighbors, then find most common class among these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self,k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def _dist(self,x1,x2):\n",
    "        return np.sqrt(np.sum((x1-x2)**2))\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def _predict(self,x,debug=False):\n",
    "        dists=np.array([self._dist(x,x_train) for x_train in self.X_train])\n",
    "        sorted_indices = np.argsort(dists)[:self.k]\n",
    "        labels = [self.y_train[i] for i in sorted_indices]\n",
    "        most_common_labels = collections.Counter(labels).most_common(1)[0][0]\n",
    "        if debug: \n",
    "            print(\"ORIGINAL: \",dists)\n",
    "            print(\"LABELS: \",labels)\n",
    "            print(\"MOST COMMON LABEL: \", most_common_labels)\n",
    "        return most_common_labels\n",
    "    \n",
    "    def predict(self,X,debug):\n",
    "        # X can have multiple samples, so predict for each one\n",
    "        out = np.array([self._predict(x,debug) for x in X])\n",
    "        if debug: print(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iris = datasets.load_iris()\n",
    "X,y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "def accuracy(y_true,y_pred):\n",
    "    return np.sum(y_true==y_pred)/len(y_true)\n",
    "\n",
    "\n",
    "k = 3\n",
    "clf = KNN(k)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions  = clf.predict(X_test,debug=False)\n",
    "print(\"Accuracy: \", accuracy(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First implement a naive implementation by directly converting numpy arrays to torch.tensors and replacing numpy functions with PyTorch functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNTorchNaive:\n",
    "    def __init__(self,k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def _dist(self,x1,x2):\n",
    "        return torch.sqrt(torch.sum((x1-x2)**2))\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def _predict(self,x,debug=False):\n",
    "        dists=torch.tensor([self._dist(x,x_train) for x_train in self.X_train])\n",
    "        sorted_indices = torch.argsort(dists)[:self.k]\n",
    "        labels = [self.y_train[i] for i in sorted_indices]\n",
    "        most_common_labels = collections.Counter(labels).most_common(1)[0][0]\n",
    "        if debug: \n",
    "            print(\"ORIGINAL: \",dists)\n",
    "            print(\"LABELS: \",labels)\n",
    "            print(\"MOST COMMON LABEL: \", most_common_labels)\n",
    "        return most_common_labels\n",
    "    \n",
    "    def predict(self,X,debug):\n",
    "        # X can have multiple samples, so predict for each one\n",
    "        out = torch.tensor([self._predict(x,debug) for x in X])\n",
    "        if debug: print(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y).long()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "def accuracy(y_true,y_pred): return torch.sum(y_true==y_pred).item()/len(y_true)\n",
    "clf = KNNTorchNaive(k)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions  = clf.predict(X_test,debug=False)\n",
    "print(\"Accuracy: \", accuracy(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 4])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNTorchBroadcast:\n",
    "    def __init__(self,k=3):\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def _predict(self,x,debug=False):\n",
    "        #print(x.shape)\n",
    "        dists = torch.sqrt(torch.sum((self.X_train-x)**2,dim=1))\n",
    "        sorted_indices = torch.argsort(dists)[:self.k]\n",
    "        labels = [self.y_train[i] for i in sorted_indices] #could perhaps be optimized, but trying to keep this consistent with collections.Counter\n",
    "        most_common_labels = collections.Counter(labels).most_common(1)[0][0]\n",
    "        if debug: \n",
    "            print(\"ORIGINAL: \",dists)\n",
    "            print(\"LABELS: \",labels)\n",
    "            print(\"MOST COMMON LABEL: \", most_common_labels)\n",
    "        return most_common_labels\n",
    "    \n",
    "    def predict(self,X,debug):\n",
    "        # X can have multiple samples, so predict for each one\n",
    "        out = torch.tensor([self._predict(x,debug) for x in X])\n",
    "        if debug: print(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Broadcasting in PyTorch follows these rules:\n",
    "\n",
    "1. If the two tensors differ in the number of dimensions, the shape of the tensor with fewer dimensions is padded with ones on its leading (left) side.\n",
    "\n",
    "2. If the shape of the two tensors does not match in any dimension, the tensor with shape equal to 1 in that dimension is stretched to match the other shape.\n",
    "\n",
    "3. If in any dimension the sizes disagree and neither is equal to 1, an error is raised.\n",
    "\n",
    "- We subtract tensor `x` of shape `[4]` from a tensor `self.X_train` of shape `[120, 4]`, PyTorch automatically broadcasts `x` to the shape of `self.X_train` by repeating it along the 0th dimension.\n",
    "    - In the *dists* calculation, the tensors differ in number of dimensions, so `x` is padded on the left with 1, becoming `[1,4]` according to Rule 1.  Then by Rule 2, this resulting tensor is \"stretched out\" along 0th dimension from shape `[1,4]` to `[120,4]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_true,y_pred): return torch.sum(y_true==y_pred).item()/len(y_true)\n",
    "clf = KNNTorchBroadcast(k)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions  = clf.predict(X_test,debug=False)\n",
    "print(\"Accuracy: \", accuracy(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mintonano",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
