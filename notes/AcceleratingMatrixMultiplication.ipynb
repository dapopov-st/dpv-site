{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Speeding up matrix multiplication ~ 5 million times\n",
        "description: Speeding up matrix multiplication in PyTorch\n",
        "date: 2024-01\n",
        "categories: [PyTorch]\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DAjDPAYs2dDV"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pickle, gzip, math, os, time, shutil, matplotlib as mpl, matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8sKL05wcRUKf"
      },
      "outputs": [],
      "source": [
        "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
        "np.set_printoptions(precision=2, linewidth=140)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ONCSxZBaLSGK"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "weights = torch.randn(100,500) #flattenned out mnist digit * 10 possible digits\n",
        "bias = torch.zeros(500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wqd3Pk3MMW19"
      },
      "outputs": [],
      "source": [
        "A = torch.randn(5,1000)\n",
        "B = torch.randn(1000,500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "batddNsy2dDm",
        "outputId": "3d1c325f-f85d-4c6f-b605-c87e2f68326e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([5, 1000]), torch.Size([1000, 500]))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.shape,B.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShN4-qOM2dDn",
        "outputId": "ddc1dfa8-4467-4180-e47a-e8b9d02eccdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5, 1000), (1000, 500))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Ar,Ac = A.shape # n_rows * n_cols\n",
        "Br,Bc = B.shape\n",
        "(Ar,Ac),(Br,Bc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-Fce2gs2dDn",
        "outputId": "bfe31abf-d245-4530-946a-243fe9df09d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 500])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C = torch.zeros(Ar, Bc) # will store product of A and B\n",
        "C.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGqPnFkTREEn"
      },
      "source": [
        "### A naive matmul for benchmarking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RvwgKNdxQg3g"
      },
      "outputs": [],
      "source": [
        "for i in range(Ar):\n",
        "  for j in range(Bc):\n",
        "    for k in range(Ac):\n",
        "      C[i,j] += A[i,k] * B[k,j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCmd4WdQ2dDn",
        "outputId": "4e7087c0-0727-47e6-ca33-6dd12706f442"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ -47.17,  -54.96,  -10.88,  ...,   21.26,    4.28,   -4.78],\n",
              "        [  77.24,   23.64,  -20.62,  ...,   13.62,  -26.03,   22.42],\n",
              "        [-108.64,   27.16,   49.40,  ...,   27.56,    9.35,   16.46],\n",
              "        [ -13.44,   45.17,   -2.30,  ...,  -79.52,  -58.32,  -13.37],\n",
              "        [ -21.50,  -12.12,   55.95,  ...,   28.55,  -32.96,  -35.81]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG2qa4UV2dDn",
        "outputId": "2b55c630-f31a-4091-fa44-d868364f6d7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 500])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOejinY3XIDN"
      },
      "source": [
        "- Also have PyTorch produce a matrix product to use as a benchmark for mathematical correctness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dpAqpc2lWrLI"
      },
      "outputs": [],
      "source": [
        "reference = torch.mm(A,B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ0NlMSrXEDA",
        "outputId": "550105e0-e7d8-4949-f645-fd24cd2a6737"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ -47.17,  -54.96,  -10.87,  ...,   21.26,    4.28,   -4.78],\n",
              "        [  77.24,   23.64,  -20.62,  ...,   13.62,  -26.03,   22.42],\n",
              "        [-108.64,   27.16,   49.40,  ...,   27.56,    9.35,   16.46],\n",
              "        [ -13.44,   45.17,   -2.30,  ...,  -79.52,  -58.32,  -13.37],\n",
              "        [ -21.50,  -12.12,   55.95,  ...,   28.55,  -32.96,  -35.81]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5rLuf8mW_lb",
        "outputId": "e109ae37-deaf-4d95-edfe-ce50d27f47d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.allclose(C.to('cpu'), reference.to('cpu'),atol=1e-04, rtol=1e-04)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xFF-ZxVl2dDo"
      },
      "outputs": [],
      "source": [
        "def matmul_naive(A,B):\n",
        "  \"\"\"\n",
        "  Perform naive matrix multiplication matrices of A and B\n",
        "  \"\"\"\n",
        "  Ar, Ac = A.shape\n",
        "  Br, Bc = B.shape\n",
        "  C = torch.zeros(Ar, Bc)\n",
        "  for i in range(Ar):\n",
        "    for j in range(Bc):\n",
        "      for k in range(Ac):\n",
        "        C[i,j] += A[i,k] * B[k,j]\n",
        "  return C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RiPl5zgRRpPc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.allclose(matmul_naive(A,B), reference,atol=1e-04, rtol=1e-04)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xYTtuVjyRpSl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performed O(2500000) operations\n"
          ]
        }
      ],
      "source": [
        "print(f\"Performed O({Ar*Bc*Ac}) operations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1c3MhapYqyN"
      },
      "source": [
        "## Matmul with numba for speeding up the dot product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JqrsI2MPRpec"
      },
      "outputs": [],
      "source": [
        "from numba import njit\n",
        "from numpy import array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bDoO4r_kRpp3"
      },
      "outputs": [],
      "source": [
        "@njit\n",
        "def dot(a,b):\n",
        "  res = 0.\n",
        "  for i in range(len(a)): res += a[i]*b[i]\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "EEs3w3PMRpyu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.0"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dot(array([1,2,3]),array([2,0,1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kMl9Fd9_Rqak"
      },
      "outputs": [],
      "source": [
        "def matmul_numba(A,B):\n",
        "  \"\"\"\n",
        "  Perform matrix multiplication matrices of A and B with\n",
        "  inner product optimized with numba\n",
        "  \"\"\"\n",
        "  Ar, Ac = A.shape\n",
        "  Br, Bc = B.shape\n",
        "  C = torch.zeros(Ar, Bc)\n",
        "  for i in range(Ar):\n",
        "    for j in range(Bc):\n",
        "      C[i,j] = dot(A[i,:],B[:,j])\n",
        "  return C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YZ4PCroKRqdT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ -47.17,  -54.96,  -10.88,  ...,   21.26,    4.28,   -4.78],\n",
              "        [  77.24,   23.64,  -20.62,  ...,   13.62,  -26.03,   22.42],\n",
              "        [-108.64,   27.16,   49.40,  ...,   27.56,    9.35,   16.46],\n",
              "        [ -13.44,   45.17,   -2.30,  ...,  -79.52,  -58.32,  -13.37],\n",
              "        [ -21.50,  -12.12,   55.95,  ...,   28.55,  -32.96,  -35.81]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matmul_numba(A.numpy(),B.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Fo-mmYWWRqgb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.allclose(matmul_numba(A.numpy(),B.numpy()), reference.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sNhhu_6XRqjj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.14 ms ± 31.3 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
          ]
        }
      ],
      "source": [
        "Anp, Bnp = A.numpy(), B.numpy()\n",
        "%timeit -n 50 matmul_numba(Anp,Bnp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bXvqgrfoRqu_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speedup factor over naive matmul: 2151\n"
          ]
        }
      ],
      "source": [
        "print(f\"Speedup factor over naive matmul: {740000/344:.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SXdRDbjsUN-"
      },
      "source": [
        "## Matmul with PyTorch inner product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZKv5QPscstM6"
      },
      "outputs": [],
      "source": [
        "def matmul_innertorch(A,B):\n",
        "  Ar, Ac = A.shape\n",
        "  Br, Bc = B.shape\n",
        "  C = torch.zeros(Ar, Bc)\n",
        "  for i in range(Ar):\n",
        "    for j in range(Bc):\n",
        "      C[i,j] = (A[i,:]*B[:,j]).sum()\n",
        "  return C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6lY3ZLG0s-Uu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ -47.17,  -54.96,  -10.88,  ...,   21.26,    4.28,   -4.78],\n",
              "        [  77.24,   23.64,  -20.62,  ...,   13.62,  -26.03,   22.42],\n",
              "        [-108.64,   27.16,   49.40,  ...,   27.56,    9.35,   16.46],\n",
              "        [ -13.44,   45.17,   -2.30,  ...,  -79.52,  -58.32,  -13.37],\n",
              "        [ -21.50,  -12.12,   55.95,  ...,   28.55,  -32.96,  -35.81]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matmul_innertorch(A,B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PjwHbFj2keF_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.allclose(reference,matmul_innertorch(A, B),atol=1e-04, rtol=1e-04)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YZJxtUBN2dDu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18 ms ± 575 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 50 _=matmul_innertorch(A, B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Ya928ptb2dDv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speedup factor over naive matmul: 839\n"
          ]
        }
      ],
      "source": [
        "print(f\"Speedup factor over naive matmul: {740000/882:.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4voepkB2dDv"
      },
      "source": [
        "## Matmul with broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXU59zNu1vPh"
      },
      "source": [
        "- We can multiply each row of A by all columns of B simultaneously.  \n",
        "- A[i,:] is [1000] of size while B is of size [1000, 10].  \n",
        "- By adding an extra dimension to A[i,:] via A[i,:,None] (or A[i,:].unsqueeze(1)), we get shape [1000, 1] and are able to broadcast along the column dimension.  \n",
        "-To put it losely, each row of A is stretched out into a column and multiplied by B; when summed, this yields a row of the final product. We then need to iterate along the rows only, reducing the number of for loops from three with naive matmul to one with broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "wbeiLnj8u_P4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "B.shape: torch.Size([1000, 500]) \n",
            "\n",
            "A[i,:].shape: torch.Size([1000]) \n",
            "\n",
            "A[i,:].unsqueeze(1).shape: torch.Size([1000, 1]) \n",
            "\n",
            "A[i,:,None].shape: torch.Size([1000, 1]) \n",
            "\n",
            "(A[i,:,None]*B).sum(dim=0).shape: torch.Size([500])\n"
          ]
        }
      ],
      "source": [
        "print(f\"\"\"B.shape: {B.shape} \\n\\nA[i,:].shape: {A[i,:].shape} \\n\n",
        "A[i,:].unsqueeze(1).shape: {A[i,:].unsqueeze(1).shape} \\n\n",
        "A[i,:,None].shape: {A[i,:,None].shape} \\n\n",
        "(A[i,:,None]*B).sum(dim=0).shape: {(A[i,:,None]*B).sum(dim=0).shape}\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHmzEVJu5Am8"
      },
      "source": [
        "- To be convinced, uncomment the line below and experiment with A[i,:].shape; A[i,:,None].shape, (A[i,:,None]\\*B).shape; (A[i,:,None]\\*B).sum(dim=0), keeping in mind that final shape is 10*5 here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "uLaNRiKYrDBI"
      },
      "outputs": [],
      "source": [
        "def matmul_broadcast(A,B):\n",
        "  Ar, Ac = A.shape\n",
        "  Br, Bc = B.shape\n",
        "  C = torch.zeros(Ar, Bc)\n",
        "  for i in range(Ar):\n",
        "    C[i] = (A[i,:,None]*B).sum(dim=0)\n",
        "    #import pdb; pdb.set_trace()\n",
        "  return C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "_nA0Whh9uHFS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ -47.17,  -54.96,  -10.88,  ...,   21.26,    4.28,   -4.78],\n",
              "        [  77.24,   23.64,  -20.62,  ...,   13.62,  -26.03,   22.42],\n",
              "        [-108.64,   27.16,   49.40,  ...,   27.56,    9.35,   16.46],\n",
              "        [ -13.44,   45.17,   -2.30,  ...,  -79.52,  -58.32,  -13.37],\n",
              "        [ -21.50,  -12.12,   55.95,  ...,   28.55,  -32.96,  -35.81]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matmul_broadcast(A,B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTS-Q1IxuZao",
        "outputId": "f8422bb3-0b48-432f-bfff-4bf479311abd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.allclose(reference,matmul_broadcast(A, B),atol=1e-04, rtol=1e-04)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e6oPwow0PHD",
        "outputId": "ed2f8219-44d4-450c-c7a0-8f96a7e0f6b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "358 μs ± 36 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 50 _=matmul_broadcast(A, B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZPewTha0Zgq",
        "outputId": "e7e21bf5-9b1c-432a-efa3-88fe07766112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speedup factor over naive matmul: 4111\n"
          ]
        }
      ],
      "source": [
        "print(f\"Speedup factor over naive matmul: {740000/180:.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4Rsc-qc2dD7"
      },
      "source": [
        "## Matmul via Einstein summation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4Y67CYG2dD7"
      },
      "source": [
        "[Einstein summation](https://ajcr.net/Basic-guide-to-einsum/) ([`einsum`](https://numpy.org/doc/stable/reference/generated/numpy.einsum.html)) is a compact representation for combining products and sums in a general way. The key rules are:\n",
        "\n",
        "- Repeating letters between input arrays means that values along those axes will be multiplied together.\n",
        "- Omitting a letter from the output means that values along that axis will be summed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Qn2wZavr6lao"
      },
      "outputs": [],
      "source": [
        "def matmul_einsum(A,B):\n",
        "  return torch.einsum('ik,kj->ij',A,B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n2H61sJ2dD9",
        "outputId": "0b81ff3e-1d65-43c3-ebf0-c70668ca8c1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The slowest run took 8.89 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "45.8 μs ± 49.8 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 50 _=matmul_einsum(A,B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8HGYJmZ7db-",
        "outputId": "ecb1c119-741f-4ba7-f332-26d08175d155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speedup factor over naive matmul: 9610\n"
          ]
        }
      ],
      "source": [
        "print(f\"Speedup factor over naive matmul: {740000/77:.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpYzulua2dD9"
      },
      "source": [
        "## Default PyTorch matmul on CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQjvbIIu2dD9"
      },
      "source": [
        "We can use pytorch's function or operator directly for matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "m5skTU3kk9Yx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.allclose(reference, A.to('cpu')@B.to('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA7gWEwu2dD9",
        "outputId": "1e19ec4c-eedb-44c9-a88a-9842f652a8e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12.5 μs ± 1.02 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
          ]
        }
      ],
      "source": [
        "# Warm-up run\n",
        "Acpu, Bcpu = A.to('cpu'),B.to('cpu')\n",
        "%timeit -n 50 _=Acpu@Bcpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6P5UnXd84s8",
        "outputId": "cdda3478-8452-46ce-a12e-eef8bc646f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speedup factor over naive matmul: 11280\n"
          ]
        }
      ],
      "source": [
        "print(f\"Speedup factor over naive matmul: {740000/65.6:.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMSC5ZYfOHId",
        "outputId": "a431ccf0-6302-4bf9-a2f0-c1910bcec013"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCzl2_upO16u"
      },
      "source": [
        "# CUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB__Fad7EdC1"
      },
      "source": [
        "- Switching device from CPU to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "9Lz3YOJfPUk_"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pickle, gzip, math, os, time, shutil, matplotlib as mpl, matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "from numba import cuda, float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YzNOGnrQna0",
        "outputId": "1e1d0712-5cac-4059-bda8-8d1faa9a0097"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwE1MlLNOEL6",
        "outputId": "dbc46bc3-a72b-4c81-9b53-6c84228b60c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 5000])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = torch.randn(5,1000,device='cuda')\n",
        "B = torch.randn(1000,5000,device='cuda')\n",
        "reference = A@B\n",
        "Ar,Ac = A.shape # n_rows * n_cols\n",
        "Br,Bc = B.shape\n",
        "C = torch.zeros(Ar, Bc) # will store product of A and B\n",
        "C.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Dsy5uoPoTcw-"
      },
      "outputs": [],
      "source": [
        "def matmul_almost_cuda(grid,a,b,c):\n",
        "  \"\"\"Fills in one piece of the grid successfully\"\"\"\n",
        "  i, j = grid\n",
        "  if i < c.shape[0] and j < c.shape[1]:\n",
        "    tmp = 0.\n",
        "    for k in range(a.shape[1]): tmp += a[i,k]*b[k,j]\n",
        "    c[i,j] = tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rwo5G-eETcon",
        "outputId": "9537f51e-fda7-4a5c-85f2-971071bb76e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-53.03,   0.00,   0.00,  ...,   0.00,   0.00,   0.00],\n",
              "        [  0.00,   0.00,   0.00,  ...,   0.00,   0.00,   0.00],\n",
              "        [  0.00,   0.00,   0.00,  ...,   0.00,   0.00,   0.00],\n",
              "        [  0.00,   0.00,   0.00,  ...,   0.00,   0.00,   0.00],\n",
              "        [  0.00,   0.00,   0.00,  ...,   0.00,   0.00,   0.00]])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matmul_almost_cuda((0,0), A, B, C)\n",
        "C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpuOKQvaUbLm"
      },
      "source": [
        "- Wiki: a compute kernel is a routine compiled for high throughput accelerators.  Kernels correspond roughly to inner loops, doing a piece of the computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ozZ71GIfTcka"
      },
      "outputs": [],
      "source": [
        "def launch_kernel(kernel,grid_x,grid_y,*args,**kwargs):\n",
        "  for i in range(grid_x):\n",
        "    for j in range(grid_y):\n",
        "      kernel((i,j),*args,**kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsvDErV5W0QZ"
      },
      "source": [
        "- The code below has the jist of what we want to do, but is not run in parallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "FcUjMDttTcfv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-53.03,  -0.23, -24.30,  ..., -11.28, -24.68, -31.85],\n",
              "        [-15.85,  13.23,  19.40,  ...,  -8.92,  28.37,  16.67],\n",
              "        [ 53.55, -15.54,  13.36,  ...,  12.86,   1.21, -12.67],\n",
              "        [ 37.49, -30.42,  13.84,  ..., -16.57,  24.10,  -3.87],\n",
              "        [  3.07,  -0.18,   4.91,  ..., -25.19, -40.16, -32.40]])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Had to keyboard interrupt, runs nowhere near reasonable time when done sequentially\n",
        "C = torch.zeros(Ar,Bc)\n",
        "# grid_x <-> Ar, grid_y <-> Bc, args: A,B,C passed to matmul_cuda\n",
        "launch_kernel(matmul_almost_cuda, Ar, Bc, A, B, C)\n",
        "C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSPi30nbW52M"
      },
      "source": [
        "- To run the code in parallel, use CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "OUMjPN_dTcYb"
      },
      "outputs": [],
      "source": [
        "from numba import cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "8-mRAkCKTcOg"
      },
      "outputs": [],
      "source": [
        "# Decorator below will compile into GPU code\n",
        "@cuda.jit\n",
        "def matmul_cuda(a,b,c):\n",
        "  # numba will pass ove the grid\n",
        "  i, j = cuda.grid(2)\n",
        "  if i < c.shape[0] and j < c.shape[1]:\n",
        "    tmp = 0.\n",
        "    for k in range(a.shape[1]): tmp += a[i,k]*b[k,j]\n",
        "    c[i,j] = tmp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnhrQeePY994"
      },
      "source": [
        "- Call each grid item in parallel with the number of different processors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0_wRmC8ZjV6",
        "outputId": "9e5e7a74-0a71-4920-eff1-409647650415"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 5000])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCdrFd-hY7gM",
        "outputId": "784a0866-f983-43bc-d3bd-9e92c6e64bdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 313)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TPB = 16\n",
        "C = torch.zeros(Ar,Bc,device='cuda')\n",
        "Cr, Cc = C.shape\n",
        "blockspergrid = (math.ceil(Cr/TPB), math.ceil(Cc/TPB))\n",
        "blockspergrid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knAHawxQTbyJ",
        "outputId": "cf67e8d5-108b-45f8-a3d5-454b78ab0653"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "D-y371FuaFFs"
      },
      "outputs": [],
      "source": [
        "#matmul_cuda[blockspergrid, (TPB, TPB)](A,B,C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6bbQdnYe8X0"
      },
      "source": [
        "### Another implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wX_PzXnTHRI"
      },
      "source": [
        "- The higher-level idea is to unroll the two outer for loops into a single row-column calculation by replacing the outer loops with two dimensions of threads.  \n",
        "#### Details\n",
        "- Every thread corresponds to one output element\n",
        "- Make a 2-D grid of threads to access it with a (row,column) pair."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAheN_UxiAFE"
      },
      "source": [
        "- Proper profiling appears to be more involved, see https://dev-discuss.pytorch.org/t/using-nsight-systems-to-profile-gpu-workload/59"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JeWQh5LUTCj",
        "outputId": "bb40a27f-ec83-4a59-8177-29fcf1bf4ad7"
      },
      "outputs": [],
      "source": [
        "from numba import cuda, float32\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "@cuda.jit\n",
        "def fast_matmul(A, B, C):\n",
        "    # Define an array in the shared memory\n",
        "    # The size and type of the arrays must be known at compile time\n",
        "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
        "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
        "\n",
        "    x, y = cuda.grid(2)\n",
        "\n",
        "    tx = cuda.threadIdx.x\n",
        "    ty = cuda.threadIdx.y\n",
        "    bpg = cuda.gridDim.x    # blocks per grid\n",
        "\n",
        "    # Each thread computes one element in the result matrix.\n",
        "    # The dot product is chunked into dot products of TPB-long vectors.\n",
        "    tmp = float32(0.)\n",
        "    for i in range(bpg):\n",
        "        # Preload data into shared memory\n",
        "        sA[ty, tx] = 0\n",
        "        sB[ty, tx] = 0\n",
        "        if y < A.shape[0] and (tx+i*TPB) < A.shape[1]:\n",
        "          sA[ty, tx] = A[y, tx + i * TPB]\n",
        "        if x < B.shape[1] and (ty+i*TPB) < B.shape[0]:\n",
        "          sB[ty, tx] = B[ty + i * TPB, x]\n",
        "\n",
        "        # Wait until all threads finish preloading\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        # Computes partial product on the shared memory\n",
        "        for j in range(TPB):\n",
        "            tmp += sA[ty, j] * sB[j, tx]\n",
        "\n",
        "        # Wait until all threads finish computing\n",
        "        cuda.syncthreads()\n",
        "    if y < C.shape[0] and x < C.shape[1]:\n",
        "        C[y, x] = tmp\n",
        "\n",
        "A_h = np.random.rand(5,1000)\n",
        "B_h = np.random.rand(1000,10)\n",
        "C_h = np.zeros([5,10])\n",
        "\n",
        "A = cuda.to_device(A_h)\n",
        "B = cuda.to_device(B_h)\n",
        "C = cuda.to_device(C_h)\n",
        "\n",
        "#TPB must be an integer between 1 and 32\n",
        "TPB = 32\n",
        "threadsperblock = (TPB, TPB)\n",
        "grid_y_max = max(A_h.shape[0],B_h.shape[0])\n",
        "grid_x_max = max(A_h.shape[1],B_h.shape[1])\n",
        "blockspergrid_x = math.ceil(grid_x_max / threadsperblock[0])\n",
        "blockspergrid_y = math.ceil(grid_y_max / threadsperblock[1])\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "fast_matmul[blockspergrid, threadsperblock](A, B, C)\n",
        "C_h = C.copy_to_host()\n",
        "print(C_h)\n",
        "print(A_h@B_h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQpUAEx7Pkf9"
      },
      "source": [
        "The single for loop in the code is sufficient because it iterates over the number of blocks per grid (bpg). Each block contains TPB x TPB threads, where TPB is the thread per block parameter. Each thread computes one element in the result matrix C, by performing a dot product of a row in A and a column in B. However, since the matrices A and B may be larger than the shared memory size of each block, the dot product is chunked into smaller segments of length TPB. This means that each thread needs to load multiple segments of data from the global memory to the shared memory, and accumulate the partial products in a temporary variable (tmp). The final value of tmp is then stored in the corresponding element of C.\n",
        "\n",
        "To illustrate this, let’s assume that TPB = 2 and bpg = 2. Suppose we have the following matrices A and B:\n",
        "\n",
        "A=[12345678910111213141516]\n",
        "A=\n",
        "​15913​261014​371115​481216​\n",
        "\n",
        "​\n",
        "\n",
        "B=[17181920212223242526272829303132]\n",
        "B=\n",
        "​17212529​18222630​19232731​20242832​\n",
        "\n",
        "​\n",
        "\n",
        "The result matrix C is:\n",
        "\n",
        "C=A×B=[2502602702806186446706969861028107011121354141214701528]\n",
        "C=A×B=\n",
        "​2506189861354​26064410281412​27067010701470​28069611121528​\n",
        "\n",
        "​\n",
        "\n",
        "The grid and block dimensions are:\n",
        "\n",
        "dim3 dim_grid (2, 2, 1); // 2 x 2 blocks per grid\n",
        "dim3 dim_block (2, 2, 1); // 2 x 2 threads per block\n",
        "\n",
        "The thread indices are:\n",
        "\n",
        "(x, y) = (0, 0), (0, 1), (1, 0), (1, 1) // within each block\n",
        "(tx, ty) = (0, 0), (0, 1), (1, 0), (1, 1) // within each thread\n",
        "\n",
        "The code will execute as follows:\n",
        "\n",
        "    For i = 0, each thread loads the first segment of data from A and B to the shared memory sA and sB. For example, the thread with (x, y) = (0, 0) and (tx, ty) = (0, 0) will load A[0, 0] and B[0, 0] to sA[0, 0] and sB[0, 0], respectively. The shared memory arrays will look like this:\n",
        "\n",
        "sA = [[1, 2], [5, 6]] // for block (0, 0)\n",
        "sA = [[9, 10], [13, 14]] // for block (1, 0)\n",
        "sA = [[3, 4], [7, 8]] // for block (0, 1)\n",
        "sA = [[11, 12], [15, 16]] // for block (1, 1)\n",
        "\n",
        "sB = [[17, 18], [21, 22]] // for block (0, 0)\n",
        "sB = [[17, 18], [21, 22]] // for block (0, 1)\n",
        "sB = [[25, 26], [29, 30]] // for block (1, 0)\n",
        "sB = [[25, 26], [29, 30]] // for block (1, 1)\n",
        "\n",
        "    After synchronizing the threads, each thread computes the partial product of the first segment using sA and sB. For example, the thread with (x, y) = (0, 0) and (tx, ty) = (0, 0) will compute tmp = sA[0, 0] * sB[0, 0] + sA[0, 1] * sB[1, 0] = 1 * 17 + 2 * 21 = 59. The other threads will compute similar values for their corresponding elements.\n",
        "\n",
        "    For i = 1, each thread loads the second segment of data from A and B to the shared memory sA and sB, overwriting the previous values. For example, the thread with (x, y) = (0, 0) and (tx, ty) = (0, 0) will load A[0, 2] and B[2, 0] to sA[0, 0] and sB[0, 0], respectively. The shared memory arrays will look like this:\n",
        "\n",
        "sA = [[3, 4], [7, 8]] // for block (0, 0)\n",
        "sA = [[11, 12], [15, 16]] // for block (1, 0)\n",
        "sA = [[1, 2], [5, 6]] // for block (0, 1)\n",
        "sA = [[9, 10], [13, 14]] // for block (1, 1)\n",
        "\n",
        "sB = [[25, 26], [29, 30]] // for block (0, 0)\n",
        "sB = [[25, 26], [29, 30]] // for block (0, 1)\n",
        "sB = [[17, 18], [21, 22]] // for block (1, 0)\n",
        "sB = [[17, 18], [21, 22]] // for block (1, 1)\n",
        "\n",
        "    After synchronizing the threads, each thread computes the partial product of the second segment using sA and sB, and adds it to the previous value of tmp. For example, the thread with (x, y) = (0, 0) and (tx, ty) = (0, 0) will compute tmp = tmp + sA[0, 0] * sB[0, 0] + sA[0, 1] * sB[1, 0] = 59 + 3 * 25 + 4 * 29 = 250. The other threads will compute similar values for their corresponding elements.\n",
        "\n",
        "    Finally, each thread stores the final value of tmp in the result matrix C.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKNxjk7rKIQF",
        "outputId": "37ac0bd7-9e6d-401e-828f-e685e70f9de4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average time elapsed: 949.6985602378845 µs\n",
            "Standard deviation of time elapsed: 33.04722920348339 µs\n"
          ]
        }
      ],
      "source": [
        "# Warm up\n",
        "for _ in range(10):\n",
        "    fast_matmul[blockspergrid, threadsperblock](A, B, C)\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "# Benchmark\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "times = []\n",
        "for _ in range(50):\n",
        "  start.record()\n",
        "  fast_matmul[blockspergrid, threadsperblock](A, B, C)\n",
        "  end.record()\n",
        "\n",
        "  # Wait for all operations to finish\n",
        "  torch.cuda.synchronize()\n",
        "\n",
        "  # Append the time in microseconds\n",
        "  times.append(start.elapsed_time(end) * 1000)\n",
        "\n",
        "# Print the average time\n",
        "print(f\"Average time elapsed: {np.mean(times)} µs\\n\\\n",
        "Standard deviation of time elapsed: {np.std(times)} µs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awpIXDhAYwSy",
        "outputId": "c137e061-857a-4feb-aedd-4b32468aaf8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72.3 µs ± 31.9 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 50 fast_matmul[blockspergrid, threadsperblock](A, B, C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKzD59P0EdCr"
      },
      "source": [
        "## Default PyTorch matmul on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xib-RwD5EdC7",
        "outputId": "144d0fed-cac2-4bf3-bdf8-fa1d5ddf8dbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17.9 µs ± 6.4 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
          ]
        }
      ],
      "source": [
        "# Warm-up run\n",
        "%timeit -n 50 _=A@B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrZ94Xc0EdC-",
        "outputId": "da47c8ee-9f26-429b-8bb6-464bb525f610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speedup factor over naive matmul: 40437\n"
          ]
        }
      ],
      "source": [
        "print(f\"Speedup factor over naive matmul: {740000/18.3:.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX9wqml5e_Ar",
        "outputId": "87358b64-b10a-4cf0-ab01-7319f923dd14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N69A6ene_Ar",
        "outputId": "a4db1aad-584c-4939-8cff-868a4dfaca66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TPB = 16\n",
        "rr,rc = r.shape\n",
        "blockspergrid = (math.ceil(rr / TPB), math.ceil(rc / TPB))\n",
        "blockspergrid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nCXP_xve_Ar"
      },
      "outputs": [],
      "source": [
        "# matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)\n",
        "# r = rg.copy_to_host()\n",
        "# torch.allclose(C, r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbOUkxOthWzV",
        "outputId": "0c90f58c-bd7e-421a-ba49-05daf1aa3d20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Tensor, numpy.ndarray)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(C),type(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBUfW7OSe_As",
        "outputId": "9b8aac41-cd22-46c7-864a-ced452c84414"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The slowest run took 136.47 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "8.26 ms ± 19.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 10\n",
        "matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)\n",
        "r = rg.copy_to_host()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfWDNFJMe_As"
      },
      "outputs": [],
      "source": [
        "r=(m1c@m2c).cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLh_IOwRe_As"
      },
      "outputs": [],
      "source": [
        "%timeit -n 10 r=(m1c@m2c).cpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMMB71Fje_As"
      },
      "source": [
        "Our broadcasting version was >500ms, and our CUDA version is around 0.5ms, which is another 1000x improvement compared to broadcasting. So our total speedup is around 5 million times!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
